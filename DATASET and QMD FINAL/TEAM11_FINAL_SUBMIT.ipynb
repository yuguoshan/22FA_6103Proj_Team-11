{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'AN ANALYSIS OF PORTUGUESE BANK MARKETING DATA '\n",
        "author: 'TEAM 11: Anjali Mudgal , Guoshan Yu and Medhasweta Sen'\n",
        "date: 'November 21, 2022'\n",
        "subtitle: 'The George Washington University (DATS 6103: An Introduction to Data Mining)'\n",
        "format:\n",
        "  html:\n",
        "    smooth-scroll: true\n",
        "    toc-location: left\n",
        "    code-fold: true\n",
        "    number-sections: true\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    toc-float: true\n",
        "---"
      ],
      "id": "fd904ae1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# INTRODUCTION\n",
        "\n",
        "Bank marketing is the practice of attracting and acquiring new customers through traditional media and digital media strategies. The use of these media strategies helps determine what kind of customer is attracted to a certain institutions. This also includes different banking institutions purposefully using different strategies to attract the type of customer they want to do business with.\n",
        "\n",
        "As a discipline, marketing has evolved over the past few decades to become what it is today. Earlier, marketing strategies were primarily a means of spreading brand awareness. Today, marketing has been reinvented to fit a much bigger role. Creating both value and revenue to the institution. It is a big step up from its previous communication role, no doubt. One that was necessitated by the evolution of three factors: the consumer, the technology, and data analytics.\n",
        "\n",
        "Marketing has evolved from a communication role to a revenue generating role. The consumer has evolved from being a passive recipient of marketing messages to an active participant in the marketing process. Technology has evolved from being a means of communication to a means of data collection and analysis. Data analytics has evolved from being a means of understanding the consumer to a means of understanding the consumer and the institution.\n",
        "\n",
        "Bank marketing strategy is increasingly focused on digital channels, including social media, video, search and connected TV. As bank and credit union marketers strive to promote brand awareness, they need a new way to assess channel ROI and more accurate data to enable personalized offers. Add to that the growing importance of purpose-driven marketing.\n",
        "\n",
        "The relentless pace of digitization is disrupting not only the established order in banking, but bank marketing strategies. Marketers at both traditional institutions and digital disruptors are feeling the pressure.\n",
        "\n",
        "Just as bank marketers begin to master one channel, consumers move to another. Many now toggle between devices on a seemingly infinite number of platforms, making it harder than ever for marketers to pin down the right consumers at the right time in the right place.\n",
        "\n",
        "![](expected-marketing-budget-changes-by-channel.png)\n",
        "\n",
        "## The Data Set\n",
        "\n",
        "The data set used in this analysis is from a Portuguese bank. The data set contains 41,188 observations and 21 variables. The variables include the following:\n",
        "\n",
        "1. - age (numeric)\n",
        "2. - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3. - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4. - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5. - default: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6. - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7. - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8. - contact: contact communication type (categorical: 'cellular','telephone')\n",
        "9. - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10. - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11. - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12. - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13. - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14. - previous: number of contacts performed before this campaign and for this client (numeric)\n",
        "15. - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "16. - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
        "17. - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
        "18. - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
        "19. - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
        "20. - nr.employed: number of employees - quarterly indicator (numeric)\n",
        "21. - balance - average yearly balance, in euros (numeric)\n",
        "22. - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n",
        "## The SMART Questions\n",
        "\n",
        "The SMART questions are as follows:\n",
        "\n",
        "## Importing the libraries\n"
      ],
      "id": "c12f5e85"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "\n",
        "from scipy.stats import zscore\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.stats.api as sms\n",
        "import statsmodels.stats.multicomp as mc\n",
        "import statsmodels.stats.outliers_influence as influence\n",
        "import statsmodels.stats.diagnostic as diag\n",
        "import statsmodels.stats.stattools as stattools\n",
        "import statsmodels.stats.anova as anova\n",
        "import statsmodels.stats.weightstats as weightstats\n",
        "import statsmodels.stats.libqsturng as libqsturng\n",
        "import statsmodels.stats.power as power\n",
        "import statsmodels.stats.proportion as proportion\n",
        "import statsmodels.stats.contingency_tables as contingency_tables\n",
        "import statsmodels.stats.multitest as multitest\n",
        "import statsmodels.stats.diagnostic as diagnostic\n",
        "import statsmodels.stats.correlation_tools as correlation_tools\n",
        "from statsmodels.formula.api import ols\n",
        "import researchpy as rp\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "# Import label encoder\n",
        "from sklearn import preprocessing\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_theme(style=\"whitegrid\")"
      ],
      "id": "30e37023",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.cluster import KMeans"
      ],
      "id": "eac0785d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from matplotlib import pyplot"
      ],
      "id": "1039d8ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing the dataset\n"
      ],
      "id": "538f401d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inputFile = \"primary.csv\"\n",
        "df = pd.read_csv(inputFile)"
      ],
      "id": "7059061e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Information about the data\n"
      ],
      "id": "7e92ba1f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.columns)\n",
        "print(df.shape)\n",
        "print(df.dtypes)\n",
        "print(df.isnull().sum())\n",
        "print(df.isnull().sum().sum())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "id": "00e839c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "## Analysing the variables \n",
        "### Job Description\n"
      ],
      "id": "bd67963d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# JOB\n",
        "plt.figure(figsize = (8, 5))\n",
        "sns.countplot(data=df,y='job',hue='y')\n",
        "plt.title(\"Type of Job Distribution\")"
      ],
      "id": "a9a1c3fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "People in management, technical are more likely to subscibe to the term deposit  \n",
        "\n",
        "\n",
        "### Marital "
      ],
      "id": "19d90c33"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MARITAL\n",
        "plt.figure(figsize = (8, 5))\n",
        "sns.countplot(data=df,y='marital',hue='y')\n",
        "plt.title(\"Type of marital Distribution\")"
      ],
      "id": "47626700",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EDUCATION \n",
        "plt.figure(figsize = (8, 5))\n",
        "sns.countplot(data=df,y='education',hue='y')\n",
        "plt.title(\"Type of education Distribution\")"
      ],
      "id": "a54e6e7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loan"
      ],
      "id": "85b3e9b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# DEFAULT\n",
        "sns.countplot(data=df,y='default',hue='y')\n",
        "plt.title(\"Type of default Distribution\")"
      ],
      "id": "6256e5a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So people who do not paid back there loans and have credits, have not subcribed to the term deposit. \n"
      ],
      "id": "bd90ac84"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# HOUSING\n",
        "sns.countplot(data=df,y='housing',hue='y')\n",
        "plt.title(\"Type of housing Distribution\")"
      ],
      "id": "64087144",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# LOAN\n",
        "sns.countplot(data=df,y='loan',hue='y')\n",
        "plt.title(\"Type of Loan Distribution\")"
      ],
      "id": "e30aa1a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* people who have loans are subscribing to term deposit less. \n",
        "\n",
        "### Contact"
      ],
      "id": "93384854"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CONTACT\n",
        "sns.countplot(data=df,y='contact',hue='y')\n",
        "plt.title(\"Type of Contact Distribution\")"
      ],
      "id": "9073df32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* since the type of communication(cellular and telephone) is not really a good indicator of subcription, we drop this variable.  \n",
        "\n",
        "#### Month"
      ],
      "id": "45883fd4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MONTH\n",
        "sns.countplot(x ='month',hue='y', data = df)\n",
        "plt.title(\"Type of Months Distribution\")"
      ],
      "id": "d74c0825",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def pieChart(x_var,title):\n",
        "    yesNo = df.groupby(x_var).size()\n",
        "    yesNo.plot(kind='pie', title=title, figsize=[8,8],\n",
        "          autopct=lambda p: '{:.2f}%({:.0f})'.format(p,(p/100)*yesNo.sum()))\n",
        "    plt.show()"
      ],
      "id": "e748034d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Term Deposit \n",
        "Distribution of y(target) variable "
      ],
      "id": "e47d26d5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pieChart('y','Percentage of yes and no target(term deposit)in dataset')"
      ],
      "id": "46209a43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "only 11.7% of enteries are for y=1, so our dataset is unbalanced. \n"
      ],
      "id": "013cd6d0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# POUTCOME\n",
        "pieChart('poutcome','Distribution of poutcome in dataset')\n",
        "df.poutcome.value_counts()\n",
        "df.groupby('poutcome').size()"
      ],
      "id": "dfda904e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are *36959   unknown* values and  1840 values with other category.\n",
        "Since, 82% of entries are unknown, 4.07% other, we will directly drop this column. \n",
        "\n",
        "\n",
        "\n",
        "## Age, duration and balance"
      ],
      "id": "f57dba46"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# plotting violen plot for duration and balance \n",
        "\n",
        "f, axes = plt.subplots(1, 2,sharex=True)\n",
        "axes[0].set_title('For duration')\n",
        "sns.violinplot( x='y',y='duration',  split=True, inner=\"quart\", ax=axes[0], data=df)\n",
        "axes[1].set_title('For balance')\n",
        "sns.violinplot( x='y',y='balance',  split=True, inner=\"quart\", ax=axes[1], data=df)\n",
        "sns.despine(left=True)\n",
        "plt.show()"
      ],
      "id": "7aca5887",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* There are outliers in duration and balance so we need to get rid of them. \n",
        "* people who have a high balance, are more likely to subscribe to term deposit. \n"
      ],
      "id": "6c94ccaa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.violinplot( x='y',y='age',  split=True, inner=\"quart\", data=df)\n",
        "plt.title('Age distribution for each response variable')\n",
        "plt.show()"
      ],
      "id": "b11ed25f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* No outliers \n",
        "* People who are old are more likely to subscribe to term deposit. \n",
        "\n",
        "\n",
        "### Day \n",
        "\n",
        "# Summary  \n",
        "## Data Cleaning \n",
        "\n",
        "* Contact is not useful so we drop it.\n",
        "* In poutcome, we have a lot of missing values so we drop it.  \n",
        "* Day is not giving any relevant infomation so we drop it. \n",
        "* Removing the unknowns \n",
        "* Remove the outliers from balance and duration.\n",
        "\n",
        "## Data Visualization\n",
        "\n",
        "# Data Cleaning \n",
        "\n",
        "## Dropping the column "
      ],
      "id": "cea1c4c0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clean_data = df.drop(['contact','poutcome','day'],axis=1)"
      ],
      "id": "7e858bd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Removing unknown from job and education"
      ],
      "id": "e067ebe6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for i in clean_data.columns:\n",
        "    if clean_data[i].dtype == np.int64:\n",
        "        pass\n",
        "    else:\n",
        "        \n",
        "        # printing names and count using loop.\n",
        "        for idx, name in enumerate(clean_data[i].value_counts().index.tolist()):\n",
        "            if name == 'unknown' or name == 'other':\n",
        "                print(f\"for {i}\")\n",
        "                print(f\"{name} : {clean_data[i].value_counts()[idx]}\")\n",
        "                if clean_data[i].value_counts()[idx] < 15000:\n",
        "                    print(f\"dropping rows with value as {name} in {i}\")\n",
        "                    clean_data = clean_data[clean_data[i] != name]"
      ],
      "id": "3c90b7c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dropping the rows \n",
        "\n",
        "\n",
        "### Dropping the rows where values are 3SD away \n",
        "\n",
        "*Balance - Outliers* \n"
      ],
      "id": "4a841b23"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "standard_deviation = clean_data[['balance']].std()\n",
        "mean = clean_data[['balance']].mean()\n",
        "clean_data['balance_outliers'] = clean_data['balance']\n",
        "clean_data['balance_outliers']= zscore(clean_data['balance_outliers'])\n",
        "print(f\"removing entries before {mean - 3*standard_deviation } and after {mean + 3*standard_deviation }\")\n",
        "three_SD = (clean_data['balance_outliers']>3) | (clean_data['balance_outliers']<-3 )\n",
        "clean_data = clean_data.drop(clean_data[three_SD].index, axis = 0, inplace = False)\n",
        "clean_data = clean_data.drop('balance_outliers', axis=1)"
      ],
      "id": "d9edab6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Duration - Outliers*\n",
        "\n",
        "### Dropping rows where the duration of calls is less than 5sec since that is irrelevant "
      ],
      "id": "d1a5e968"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "less_5 = (clean_data['duration']<5)\n",
        "clean_data = clean_data.drop(clean_data[less_5].index, axis = 0, inplace = False)"
      ],
      "id": "56b8574f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Changing unit of duration from seconds to minutes to make more sense\n"
      ],
      "id": "bee6466b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clean_data['duration'] = clean_data['duration'].apply(lambda n:n/60).round(2)"
      ],
      "id": "55e59a69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Visualization \n",
        "\n",
        "### Contact versus Subscription month wise\n",
        "\n",
        "### Number of calls versus Duration and affect on subscription"
      ],
      "id": "fe760249"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "dur_cam = sns.lmplot(x='duration', y='campaign',data = clean_data,\n",
        "                     hue = 'y',\n",
        "                     fit_reg = False,\n",
        "                     scatter_kws={'alpha':0.6}, height =7)\n",
        "\n",
        "plt.axis([0,65,0,65])\n",
        "plt.ylabel('Number of Calls')\n",
        "plt.xlabel('Duration of Calls (Minutes)')\n",
        "plt.title('The Relationship between the Number and Duration of Calls (with y)')\n",
        "\n",
        "# Annotation\n",
        "plt.axhline(y=5, linewidth=2, color=\"k\", linestyle='--')\n",
        "plt.annotate('Higher subscription rate when number of calls <5 ',xytext = (35,13),\n",
        "             arrowprops=dict(color = 'k', width=1),xy=(30,6))\n",
        "plt.show()"
      ],
      "id": "0119af2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking between pdays and previous as well\n",
        "\n",
        "13. - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14. - previous: number of contacts performed before this campaign and for this client (numeric)"
      ],
      "id": "5b0a6994"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "dur_cam = sns.lmplot(x='pdays', y='previous',data = clean_data,\n",
        "                     hue = 'y',\n",
        "                     fit_reg = False,\n",
        "                     scatter_kws={'alpha':0.6}, height =7)\n",
        "\n",
        "# plt.axis([0,65,0,65])\n",
        "plt.ylabel('pdays')\n",
        "plt.xlabel('previous')\n",
        "plt.title('The Relationship between number of contacts  and last contactbefore this campaign (with y)')\n",
        "\n",
        "plt.show()"
      ],
      "id": "5e117372",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Smart Question \n",
        "Based on last contact info only number of contacts performed during this campaign is contributing a lot towards subscription rates. \n",
        "\n",
        "\n",
        "### Month wise subscription"
      ],
      "id": "93b33d42"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#converting y values \n",
        "# bankdata['y'] = bankdata['y'].apply(lambda x: 'no' if x == 'yes' else 1)\n",
        "# bankdata['y'] = bankdata['y'].astype('category')\n",
        "\n",
        "#value count for each month\n",
        "month = clean_data['month'].value_counts().rename_axis('month').reset_index(name='counts')\n",
        "#for sequencing the month\n",
        "m1_list=['jan','feb','mar','apr','may','jun','jul','aug','sep','nov','dec']\n",
        "m1=pd.DataFrame(m1_list,columns=['month'])\n",
        "#now the dataset is sequeced\n",
        "month = m1.merge(month)\n",
        "#month - counts\n",
        "#% of people contacted in that month \n",
        "month['Contact Rate'] = month['counts']*100/month['counts'].sum()\n",
        "#percentage of people contacted in that month \n",
        "# y response \n",
        "month_y = pd.crosstab(clean_data['y'],clean_data['month']).apply(lambda x: x/x.sum() * 100)\n",
        "#% of 0 and 1 for each month \n",
        "month_y = month_y.transpose()\n",
        "month_y.rename(columns = {'y':'month',0:'no', 1:'yes'}, inplace = True)\n",
        "\n",
        "# month_y\n",
        "# y | no% | yes%"
      ],
      "id": "f6ac0edf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#month = month.merge(month_y)\n",
        "month['yes'] = \" \"\n",
        "month['no'] = \" \"\n",
        "#to make it in sequence \n",
        "def addingCrossTab(): \n",
        "    for i, val in enumerate(m1_list):\n",
        "        #print (i, \",\",val)\n",
        "        month['yes'].iloc[i]=month_y.loc[val].loc['yes']\n",
        "        #print(month_y.loc[val].loc['yes'])\n",
        "        month['no'].iloc[i]=month_y.loc[val].loc['no']\n",
        "        \n",
        "addingCrossTab()  \n",
        "#print(month)      \n",
        "#print(month_y)\n",
        "# month['Subscription Rate'] = month_y['yes']\n",
        "# month['% NotSubscription'] = month_y['no']\n",
        "month.rename(columns = {'yes':'Subscription Rate','no':'NotSubscribed Rate'}, inplace = True)\n",
        "#month.drop('month_int',axis = 1,inplace = True)\n",
        "print(month)"
      ],
      "id": "267f756a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_month = month[['month','Subscription Rate','Contact Rate']].plot(x='month',kind ='line',\n",
        "                                                          figsize = (10,6),\n",
        "                                                          marker = 'o')\n",
        "\n",
        "plt.title('Subscription vs. Contact Rate by Month')\n",
        "plt.ylabel('Subscription and Contact Rate')\n",
        "plt.xlabel('Month')"
      ],
      "id": "053acc0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Maximum percentage of people have subscribed in the month of March but bank is contacting people more in the month of May. \n",
        "So it's better to contact customer's based on the subcription rate plot. \n",
        "\n",
        "# Checking the Financially stable population"
      ],
      "id": "a56dff9c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_vis = clean_data.copy()"
      ],
      "id": "a9ef647e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Job "
      ],
      "id": "22a7bcd0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_job = pd.crosstab(data_vis['y'],data_vis['job']).apply(lambda x: x/x.sum() * 100)\n",
        "y_job = y_job.transpose()\n",
        "\n",
        "y_job.rename(columns = {'y':'job',0:'no', 1:'yes'}, inplace = True)\n",
        "jobs_sub = y_job['yes'].sort_values(ascending = True).plot(kind ='barh')\n",
        "                                                                               \n",
        "plt.title('Subscription Rate by Job')\n",
        "plt.xlabel('Subscription Rate')\n",
        "plt.ylabel('Job Category')\n",
        "# Label each bar\n",
        "for patch_i, label in zip(jobs_sub.patches,\n",
        "                      y_job['yes'].sort_values(ascending = True).round(1).astype(str)):\n",
        "    jobs_sub.text(patch_i.get_width()+1.5, \n",
        "                  patch_i.get_y()+ patch_i.get_height()-0.5, \n",
        "                  label+'%', \n",
        "                  ha = 'center', \n",
        "                  va='bottom')"
      ],
      "id": "a2643356",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "job_contact=  data_vis['job'].value_counts().rename_axis('job').reset_index(name='counts')        \n",
        "job_contact['Contact Rate']= job_contact['counts']*100/job_contact['counts'].sum()  \n",
        "job_contact['Contact Rate'] = job_contact['Contact Rate'].round(2)\n",
        "job_contact=job_contact.drop(['counts'],axis=1)\n",
        "\n",
        "# job_contact['Contact Rate']= job_contact['Contact Rate'].sort_values(ascending = False)\n",
        "job_contact_plot = job_contact.plot(x='job',kind ='barh')  \n",
        "#.plot(kind ='barh')                                                \n",
        "plt.title('Contact Rate by Job')\n",
        "plt.xlabel('Contact Rate')\n",
        "plt.ylabel('Job Category')\n",
        "# Label each bar\n",
        "for patch_i, label in zip(job_contact_plot.patches,\n",
        "                      job_contact['Contact Rate'].astype(str)):\n",
        "    job_contact_plot.text(patch_i.get_width()+1.5, \n",
        "                  patch_i.get_y()+ patch_i.get_height()-0.5, \n",
        "                  label+'%', \n",
        "                  ha = 'center', \n",
        "                  va='bottom')"
      ],
      "id": "b3d4a0dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "People in blue color and managemnet jobs are contacted more, which should not be the case. \n",
        "\n",
        "## Balance"
      ],
      "id": "410edbe9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#max = 10399\n",
        "#min = -6847\n",
        "def balance_group(bal):\n",
        "    balGroup = 'Negative' if bal < 0 else 'low balance' if bal < 1000 else 'moderate balance' if bal < 2500 else 'high balance'\n",
        "    return balGroup\n",
        "data_vis['balGroup'] = data_vis['balance'].apply(balance_group)"
      ],
      "id": "e5903038",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "checking the subscription based on y value "
      ],
      "id": "4d58560c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_balance = pd.crosstab(data_vis['y'],data_vis['balGroup']).apply(lambda x: x/x.sum() * 100)\n",
        "y_balance = y_balance.transpose()"
      ],
      "id": "99827630",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cheking the subscriptions in each balance groups "
      ],
      "id": "ff99ea77"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bal = pd.DataFrame(data_vis['balGroup'].value_counts().rename_axis('balGroup').reset_index(name='counts'))\n",
        "bal_y = bal.merge(y_balance,on='balGroup')\n",
        "\n",
        "bal_y['% Contacted'] = bal_y['counts']*100/bal_y['counts'].sum()\n",
        "bal_y['% Subscription'] = bal_y[1]\n",
        "bal_y.rename(columns = {'y':'month',0:'no', 1:'yes'}, inplace = True)\n",
        "\n",
        "bal_y = bal_y.drop(['counts','no','yes'],axis=1)\n",
        "print(bal_y)\n",
        "\n",
        "bal_list = ['Negative','low balance', 'moderate balance','high balance']\n",
        "balanceGroupInfo =pd.DataFrame(bal_list,columns=['balanceGroup'])\n",
        "balanceGroupInfo['Contact Rate'] = \" \"\n",
        "balanceGroupInfo['Subscription Rate'] = \" \"\n",
        "bal_y = bal_y.set_index(['balGroup'])\n",
        "\n",
        "\n",
        "for i,val in enumerate(bal_list):\n",
        "     balanceGroupInfo['Contact Rate'].iloc[i]=bal_y.loc[val].loc['% Contacted']\n",
        "     balanceGroupInfo['Subscription Rate'].iloc[i]=bal_y.loc[val].loc['% Subscription']\n",
        "print(balanceGroupInfo)\n",
        "#bal['bal'] = [1,2,0,3]\n",
        "#bal = bal.sort_values('bal',ascending = True)"
      ],
      "id": "d6842702",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "balanceGroupInfo.plot(x='balanceGroup', kind='bar', stacked=False,\n",
        "        title='Balance Group Contact Rates and Subscription')\n",
        "plt.show()"
      ],
      "id": "ae465912",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "People with moderate to high balance, are contacted less but they have high subscription rates so bank should target them more. \n",
        "\n",
        "\n",
        "Balance Group versus Job "
      ],
      "id": "d54710c9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# add the values for 1 \n",
        "job_balance = pd.DataFrame(data_vis.groupby(['job','balGroup'])['y'].sum())\n",
        "# total number of values \n",
        "job_balance_count = pd.DataFrame(data_vis.groupby(['job','balGroup'])['y'].count())\n",
        "\n",
        "job_balance['y'] = (job_balance['y']/job_balance_count['y'])*100\n",
        "job_balance = job_balance.unstack()\n",
        "job_balance = job_balance.plot(kind='bar',figsize = (10,6))\n",
        "plt.title('Subscription Rates for each balance group in job category')"
      ],
      "id": "8cca6265",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Student and Retired are more likely to subscribe and usually have moderate to high balance. \n"
      ],
      "id": "101baa58"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "job_balance_count1 = job_balance_count.unstack()\n",
        "job_balance_count1 = job_balance_count1.plot(kind='bar',figsize = (10,6))\n",
        "plt.title('Contact for each balance group in job category')"
      ],
      "id": "c2a40bbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loan \n",
        "covered loan in initial EDA "
      ],
      "id": "7eefc4c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_encode = data_vis.copy()"
      ],
      "id": "d5d42dbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Data Ready for Modelling \n",
        "\n",
        "## Encoding\n",
        "\n",
        "One Hot Encoding "
      ],
      "id": "6e0ed566"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_encode = pd.get_dummies(data_encode, columns = ['housing'])\n",
        "data_encode = pd.get_dummies(data_encode, columns = ['loan'])\n",
        "data_encode = pd.get_dummies(data_encode, columns = ['default'])\n",
        "data_encode = pd.get_dummies(data_encode, columns = ['job'])\n",
        "data_encode = pd.get_dummies(data_encode, columns = ['education'])\n",
        "data_encode = pd.get_dummies(data_encode, columns = ['marital'])"
      ],
      "id": "202c6cae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sin - Cos encoding "
      ],
      "id": "860e1390"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math\n",
        "from math import pi\n",
        "def sin_transformation(x):\n",
        "    x=x-1\n",
        "    sin_x = math.sin((2*pi*x)/11)\n",
        "    return sin_x\n",
        "def cos_transformation(x):\n",
        "    x=x-1\n",
        "    cos_x = math.cos((2*pi*x)/11)\n",
        "    return cos_x\n",
        "data_encode['sin_month'] = data_encode['month_int'].apply(sin_transformation) \n",
        "data_encode['cos_month'] = data_encode['month_int'].apply(cos_transformation)  "
      ],
      "id": "e108c401",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.scatterplot(data=data_encode,x='sin_month',y='cos_month')"
      ],
      "id": "b8d8a925",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Label Encoding "
      ],
      "id": "7c8a69a5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_encode= data_encode.drop(['month'],axis=1)\n",
        "#data_encode= data_encode.drop(['month_int'],axis=1)\n",
        "data_encode = data_encode.drop(['balGroup'],axis=1)\n",
        "data_encode = data_encode.drop(['pdays'],axis=1)"
      ],
      "id": "43de2353",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkpoint"
      ],
      "id": "9e0db05a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#data_encode.to_csv('Dataset/final_encoded.csv',index=False)\n",
        "#data_encode =  pd.read_csv('Dataset/final_encoded.csv')"
      ],
      "id": "4c46e632",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_model = data_encode.copy()"
      ],
      "id": "759ae31c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dropping the unecessary varibles for modelling "
      ],
      "id": "7c0c9082"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_model=data_model.drop(['cons.conf.idx', 'emp.var.rate', 'euribor3m', 'nr.employed',\n",
        "       'cons.price.idx'],axis=1)"
      ],
      "id": "547707e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Splitting our Dataset "
      ],
      "id": "010fe8ad"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#dropping y to extract x variables \n",
        "x = data_model.drop(['y'],axis=1)\n",
        "#y variables\n",
        "y = data_model['y']\n",
        "#splitting the dataset \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
      ],
      "id": "af30a390",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Balancing Our Dataset"
      ],
      "id": "29e021fb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sm = SMOTE(random_state=42)\n",
        "train_sx, train_sy = sm.fit_resample(x_train, y_train)\n",
        "test_sx, test_sy = sm.fit_resample(x_test, y_test)\n",
        "#printing x and y values \n",
        "np.bincount(train_sy)"
      ],
      "id": "15a94738",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_sx['sin_month'] = train_sx['month_int'].apply(sin_transformation) \n",
        "train_sx['cos_month'] = train_sx['month_int'].apply(cos_transformation) \n",
        "\n",
        "sns.scatterplot(data=train_sx,x='sin_month',y='cos_month')"
      ],
      "id": "3940d01f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_sx= train_sx.drop(['month_int'],axis=1)\n",
        "test_sx=test_sx.drop(['month_int'],axis=1)"
      ],
      "id": "6e93c115",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_train= x_train.drop(['month_int'],axis=1)\n",
        "x_test=x_test.drop(['month_int'],axis=1)"
      ],
      "id": "ae19a295",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkpoint 2"
      ],
      "id": "eda568ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_balanced = pd.concat([train_sx, train_sy], axis=1)\n",
        "train_unbalanced = pd.concat([x_train, y_train], axis=1)\n",
        "\n",
        "test_unbalanced = pd.concat([x_test, y_test], axis=1)\n",
        "test_balanced = pd.concat([test_sx, test_sy], axis=1)\n",
        "\n",
        "# train_balanced.to_csv('Dataset/train_balanced.csv',index=False)\n",
        "# train_unbalanced.to_csv('Dataset/train_unbalanced.csv',index=False)\n",
        "# test_unbalanced.to_csv('Dataset/test_unbalanced.csv',index=False)\n",
        "# test_balanced.to_csv('Dataset/test_balanced.csv',index=False)\n",
        "# print(\"Before Smote\")\n",
        "# print(f\"for training : {np.bincount(y_train)}\")\n",
        "# print(f\"for testing : {np.bincount(y_test)}\")\n",
        "# print(\"After smote\")\n",
        "# print(f\"for training : {np.bincount(y_res)}\")\n",
        "# print(f\"for testing : {np.bincount(test_sy)}\")"
      ],
      "id": "ba8d2d3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "balanced_train= pd.read_csv('Dataset/train_balanced.csv')\n",
        "balanced_test= pd.read_csv('Dataset/test_balanced.csv')\n",
        "unbalanced_train= pd.read_csv('Dataset/train_unbalanced.csv')\n",
        "unbalanced_test= pd.read_csv('Dataset/train_unbalanced.csv')"
      ],
      "id": "2cad4c3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# define standard scaler\n",
        "scaler = StandardScaler()\n",
        "# transform data\n",
        "balanced_train[['age','balance','duration']]= scaler.fit_transform(balanced_train[['age','balance','duration']])\n",
        "\n",
        "balanced_test[['age','balance','duration']]= scaler.fit_transform(balanced_test[['age','balance','duration']])\n",
        "\n",
        "unbalanced_train[['age','balance','duration']]= scaler.fit_transform(unbalanced_train[['age','balance','duration']])\n",
        "\n",
        "unbalanced_test[['age','balance','duration']]= scaler.fit_transform(unbalanced_test[['age','balance','duration']])"
      ],
      "id": "22a739ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_train = unbalanced_train.drop(['y'],axis=1)\n",
        "x_test = unbalanced_test.drop(['y'],axis=1)\n",
        "y_train = unbalanced_train['y']\n",
        "y_test = unbalanced_test['y']"
      ],
      "id": "adf76af4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bx_train = balanced_train.drop(['y'],axis=1)\n",
        "bx_test = balanced_test.drop(['y'],axis=1)\n",
        "by_train = balanced_train['y']\n",
        "by_test = balanced_test['y']"
      ],
      "id": "8569da0b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Modeling\n",
        "## Logistic Regression\n",
        "### Feature Selection \n",
        "\n",
        "rfe_model = RFE(LogisticRegression(solver='lbfgs', max_iter=1000), step= 25)\n",
        "rfe_model = rfe_model.fit(x_train,y_train)\n",
        "\n",
        "# feature selection\n",
        "print(rfe_model.support_)\n",
        "print(rfe_model.ranking_)\n",
        "\n",
        "selected_columns = x_train.columns[rfe_model.support_]\n",
        "print(selected_columns.tolist())"
      ],
      "id": "ac2c287b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_final = x_train[selected_columns.tolist()]\n",
        "X_test_final = x_test[selected_columns.tolist()]"
      ],
      "id": "dabfd94e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lr = LogisticRegression(random_state=123)\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "print(f\"Accuracy for training set {accuracy_score(y_train, lr.predict(x_train))}\")\n",
        "print(f\"Accuracy for testing set {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"Confusion matrix \\n{confusion_matrix(y_test, y_pred)}\")\n",
        "print(f\"{classification_report(y_test, y_pred)}\")"
      ],
      "id": "20ba3c23",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "classifiers = [lr]"
      ],
      "id": "2db332c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "#ConfusionMatrixDisplay.from_estimator(lr, x_test, y_test)\n",
        "cut_off = 0.20\n",
        "precision = []\n",
        "recall = []\n",
        "accuracy =[]\n",
        "\n",
        "def checking_cutoff(cutoff):\n",
        "    predictions = (lr.predict_proba(x_test)[:,1]>cutoff).astype(int)\n",
        "    ConfusionMatrixDisplay.from_estimator(lr, x_test, y_test)\n",
        "    print(f\"cutoff = {cutoff:.2f}\")\n",
        "    dictionary = classification_report(y_test, predictions,output_dict=True)\n",
        "    #plot_confusion_matrix(lr, x_test, y_test)\n",
        "    #plt.show()\n",
        "    #accuracy.append(float(dictionary['accuracy']))\n",
        "    print(f\"Accuracy : {dictionary['accuracy']:.2f}\\nPrecision : {dictionary['1']['precision']:.2f} \\nRecall : {dictionary['1']['recall']:.2f}\")\n",
        "    print(f\"Confusion matrix \\n{confusion_matrix(y_test, predictions)}\")\n",
        "\n",
        "cutoffs = np.linspace(0,0.5,5)\n",
        "for i in cutoffs:\n",
        "    checking_cutoff(i)\n",
        "print(\"\\nReady to continue.\")"
      ],
      "id": "ef9e1b8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Precision-Recall vs Threshold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#y_pred=logit.predict(x_test)\n",
        "y_pred_probs=lr.predict_proba(x_test) \n",
        "# probs_y is a 2-D array of probability of being labeled as 0 (first \n",
        "# column of array) vs 1 (2nd column in array)\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs[:, 1]) \n",
        "#retrieve probability of being 1(in second column of probs_y)\n",
        "pr_auc = metrics.auc(recall, precision)\n",
        "\n",
        "plt.title(\"Precision-Recall vs Threshold Chart\")\n",
        "plt.plot(thresholds, precision[: -1], \"b--\", label=\"Precision\")\n",
        "plt.plot(thresholds, recall[: -1], \"r--\", label=\"Recall\")\n",
        "plt.ylabel(\"Precision, Recall\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.ylim([0,1])\n",
        "\n",
        "print(\"\\nReady to continue.\")"
      ],
      "id": "80bb5de9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on this curve, we would choose the cut off value as 0.25\n",
        "\n",
        "Roc - Auc Curve "
      ],
      "id": "8e7e7128"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Receiver Operator Characteristics (ROC)\n",
        "# Area Under the Curve (AUC)\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "# predict probabilities\n",
        "lr_probs = lr.predict_proba(x_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(y_test, ns_probs)\n",
        "lr_auc = roc_auc_score(y_test, lr_probs)\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "# calculate roc curves\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "# plot the roc curve for the model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "# aXis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "id": "3d8b4181",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "\n",
        "display = PrecisionRecallDisplay.from_estimator(\n",
        "    lr, x_test, y_test, name=\"Logistic Regression\"\n",
        ")\n",
        "_ = display.ax_.set_title(\"Precision-Recall curve\")"
      ],
      "id": "0871231d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Decision Tree \n",
        "\n",
        "## Feature Selection"
      ],
      "id": "9fa03714"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# feature selection\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(x_train, y_train)\n",
        "importance = dtc.feature_importances_\n",
        "features = [] \n",
        "imp = []\n",
        "for i,v in enumerate(importance):\n",
        "    if v >0.01:\n",
        "        print(f\"Feature {i} variable {x_train.columns[i]} score {v:.2f}\")\n",
        "        features.append(x_train.columns[i])\n",
        "        imp.append(v)\n",
        "print(features)\n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.show()"
      ],
      "id": "d70223d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_train_ba,y_train_ba = x_train[features],y_train\n",
        "x_test_un,y_test_un = x_test[features],y_test\n",
        "\n",
        "dtc = DecisionTreeClassifier(criterion='entropy',max_depth=6,splitter='best')\n",
        "dtc.fit(x_train_ba,y_train_ba )\n",
        "dtcprediction = dtc.predict(x_test_un)\n",
        "print(accuracy_score(y_test_un, dtcprediction))\n",
        "print(confusion_matrix(y_test_un, dtcprediction))\n",
        "print(classification_report(y_test_un, dtcprediction))"
      ],
      "id": "1d69dcac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Creating a dictionary of parameters to use in GridSearchCV\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# params = {\n",
        "#     'criterion':  ['gini', 'entropy'],\n",
        "#     'max_depth':  [None, 2, 4, 6, 8, 10],\n",
        "#     'max_features': [None, 'sqrt', 'log2', 0.2, 0.4, 0.6, 0.8],\n",
        "#     'splitter': ['best', 'random']\n",
        "# }\n",
        "\n",
        "# clf = GridSearchCV(\n",
        "#     estimator=DecisionTreeClassifier(),\n",
        "#     param_grid=params,\n",
        "#     cv=5,\n",
        "#     n_jobs=5,\n",
        "#     verbose=1,\n",
        "# )\n",
        "\n",
        "# clf.fit(x_train, y_train)\n",
        "# print(clf.best_params_)"
      ],
      "id": "e56f6dec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "classifiers.append(dtc)"
      ],
      "id": "fd41873c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drawing the tree"
      ],
      "id": "2f6692d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# from sklearn import tree\n",
        "# fig = plt.figure(figsize=(25,20))\n",
        "# _ = tree.plot_tree(dtc, \n",
        "#                    filled=True)\n",
        "# # from sklearn.tree import export_graphviz\n",
        "# from sklearn.externals.six import StringIO  \n",
        "# from IPython.display import Image  \n",
        "# import pydotplus\n",
        "\n",
        "# dot_data = StringIO()\n",
        "# export_graphviz(dtc, out_file=dot_data,  \n",
        "#                 filled=True, rounded=True,\n",
        "#                 special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
        "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "# graph.write_png('dt.png')\n",
        "# Image(graph.create_png())"
      ],
      "id": "0607883a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Forest \n"
      ],
      "id": "7267945b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(x_train, y_train)\n",
        "rfcpredictions = rfc.predict(x_test)\n",
        "print(accuracy_score(y_test, rfcpredictions ))\n",
        "print(confusion_matrix(y_test, rfcpredictions ))\n",
        "print(classification_report(y_test, rfcpredictions ))"
      ],
      "id": "af0c5423",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear SVC "
      ],
      "id": "c7f94353"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "svc_linear = LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
        "          multi_class='ovr', penalty='l2', random_state=123, tol=0.0001,\n",
        "          verbose=0)\n",
        "svc_linear.fit(x_train,y_train)\n",
        "svc_linear_predictions = svc_linear.predict(x_test)\n",
        "print(accuracy_score(y_test, svc_linear_predictions))\n",
        "print(confusion_matrix(y_test, svc_linear_predictions))\n",
        "print(classification_report(y_test, svc_linear_bapredictions))"
      ],
      "id": "a550d2f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "classifiers.append(rfc)\n",
        "classifiers.append(svc_linear)"
      ],
      "id": "1b7de02a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SVC\n"
      ],
      "id": "3747ea35"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#  SVM - Support Vector Machines balance check on unbalance test\n",
        "svc= SVC(kernel='poly', random_state=123)\n",
        "svc.fit(x_train,y_train)\n",
        "svcpredictions = svc.predict(x_test)\n",
        "print(accuracy_score(y_test, svcpredictions))\n",
        "print(confusion_matrix(y_test, svcpredictions))\n",
        "print(classification_report(y_test, svcpredictions))"
      ],
      "id": "48180c61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Naive Bayes "
      ],
      "id": "4012205b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "modelNB = GaussianNB()\n",
        "modelNB.fit(x_train,y_train)\n",
        "print(f\"Model score is {modelNB.score(x_test,y_test)}\")\n",
        "def modelProbability(prediction0,prediction1,y):\n",
        "    plt.figure(figsize=(15,7))\n",
        "    plt.hist(prediction1[y==0], bins=50, label='No_pred1', alpha=0.7, color='g')\n",
        "    plt.hist(prediction0[y==0], bins=50, label='No_pred0')\n",
        "    plt.hist(prediction0[y==1], bins=50, label='Yes_pred0', alpha=0.7, color='r')\n",
        "    plt.hist(prediction1[y==1], bins=50, label='Yes_pred1', alpha=0.7, color='y')\n",
        "    plt.xlabel('Probability of being Positive Class', fontsize=25)\n",
        "    plt.ylabel('Number of records in each bucket', fontsize=25)\n",
        "    plt.legend(fontsize=15)\n",
        "    plt.tick_params(axis='both', labelsize=25, pad=5)\n",
        "    plt.show() \n",
        "pred1=modelNB.predict_proba(x_test)[:,0]\n",
        "pred2 = modelNB.predict_proba(x_test)[:,1]\n",
        "modelProbability(pred1,pred2,y_test)"
      ],
      "id": "43a6da62",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "classifiers.append(svc)\n",
        "classifiers.append(modelNB)"
      ],
      "id": "fccd375b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#modelling\n",
        "def modelEvaluation(model,x,y):\n",
        "    print('test set evaluation: ')\n",
        "    y_pred = model.predict(x)\n",
        "    print(accuracy_score(y, y_pred))\n",
        "    print(confusion_matrix(y, y_pred))\n",
        "    print(classification_report(y, y_pred))\n",
        "    \n",
        "modelEvaluation(modelNB,x_test,y_test)"
      ],
      "id": "db9e9e4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KNN \n"
      ],
      "id": "a70a6ab6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "acc = []\n",
        "prec = []\n",
        "# Will take some time\n",
        "from sklearn import metrics\n",
        "for i in range(1,40):\n",
        "    neigh = KNeighborsClassifier(n_neighbors = i).fit(x_train,y_train)\n",
        "    y_pred = neigh.predict(x_test)\n",
        "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
        "    prec.append((metrics.average_precision_score(y_test, y_pred)))"
      ],
      "id": "7ca5e529",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,40),acc,color = 'blue',linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10)\n",
        "plt.title('accuracy vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Accuracy')\n",
        "print(\"Maximum accuracy:-\",max(acc),\"at K =\",acc.index(max(acc)))"
      ],
      "id": "a52ace79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,40),prec,color = 'blue',linestyle='dashed', \n",
        "         marker='o',markerfacecolor='red', markersize=10)\n",
        "plt.title('precision vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Precision')\n",
        "print(\"Maximum Precision:-\",max(prec),\"at K =\",prec.index(max(prec)))"
      ],
      "id": "fa9a8557",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mrroger = 3\n",
        "knn = KNeighborsClassifier(n_neighbors=mrroger) # instantiate with n value given\n",
        "knn.fit(x_train,y_train)\n",
        "y_pred = knn.predict(x_test)\n",
        "#y_pred = knn.predict_proba(x_test)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "id": "f1a065f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# K Means\n"
      ],
      "id": "8a622e51"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# K-means \n",
        "# \n",
        "from sklearn.cluster import KMeans\n",
        "km_X = KMeans( n_clusters=2, init='random', n_init=10, max_iter=300, tol=1e-04, random_state=0 )\n",
        "y_km = km_X.fit_predict(x_train)\n",
        "\n",
        "y_pred = km_X.predict(x_test)\n",
        "#y_pred = knn.predict_proba(x_test)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "index1 = 0\n",
        "index2 = 1\n",
        "\n",
        "plt.scatter( x_train[y_km==0].iloc[:,index1], x_train[y_km==0].iloc[:,index2], s=50, c='lightgreen', marker='s', edgecolor='black', label='cluster 1' )\n",
        "\n",
        "plt.scatter( x_train[y_km==1].iloc[:,index1], x_train[y_km==1].iloc[:,index2], s=50, c='orange', marker='o', edgecolor='black', label='cluster 2' )\n",
        "\n",
        "plt.scatter( x_train[y_km==2].iloc[:,index1], x_train[y_km==2].iloc[:,index2], s=50, c='lightblue', marker='v', edgecolor='black', label='cluster 3' )\n",
        "\n",
        "# plot the centroids\n",
        "plt.scatter( km_X.cluster_centers_[:, index1], km_X.cluster_centers_[:, index2], s=250, marker='*', c='red', edgecolor='black', label='centroids' )\n",
        "plt.legend(scatterpoints=1)\n",
        "plt.xlabel(str(index1) + \" : \" + x_train.columns[index1])\n",
        "plt.ylabel(str(index2) + \" : \" + x_train.columns[index2])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "699713f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Precision-Recall vs Threshold\n",
        "y_pred_probs=lr.predict_proba(x_test) \n",
        "# probs_y is a 2-D array of probability of being labeled as 0 (first \n",
        "# column of array) vs 1 (2nd column in array)\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs[:, 1]) \n",
        "#retrieve probability of being 1(in second column of probs_y)\n",
        "pr_auc = metrics.auc(recall, precision)\n",
        "\n",
        "plt.title(\"Precision-Recall vs Threshold Chart\")\n",
        "plt.plot(thresholds, precision[: -1], \"b--\", label=\"Precision\")\n",
        "plt.plot(thresholds, recall[: -1], \"r--\", label=\"Recall\")\n",
        "plt.ylabel(\"Precision, Recall\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.ylim([0,1])\n",
        "\n",
        "print(\"\\nReady to continue.\")"
      ],
      "id": "33013fca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on this curve, we would choose the cut off value as 0.25\n",
        "\n",
        "Roc - Auc Curve "
      ],
      "id": "44b4d1ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Receiver Operator Characteristics (ROC)\n",
        "# Area Under the Curve (AUC)\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "# predict probabilities\n",
        "lr_probs = lr.predict_proba(x_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(y_test, ns_probs)\n",
        "lr_auc = roc_auc_score(y_test, lr_probs)\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "# calculate roc curves\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "# plot the roc curve for the model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "# aXis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "id": "b642c9e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Comparison\n"
      ],
      "id": "0750dd66"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#set up plotting area\n",
        "plt.figure(0).clf()\n",
        "\n",
        "#fit logistic regression model and plot ROC curve\n",
        "# model = LogisticRegression()\n",
        "# model.fit(X_train, y_train)\n",
        "# y_pred = model.predict_proba(X_test)[:, 1]\n",
        "# fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
        "# auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
        "# plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
        "\n",
        "#fit gradient boosted model and plot ROC curve\n",
        "# model = GradientBoostingClassifier()\n",
        "# model.fit(X_train, y_train)\n",
        "# y_pred = model.predict_proba(X_test)[:, 1]\n",
        "# fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
        "# auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
        "# plt.plot(fpr,tpr,label=\"Gradient Boosting, AUC=\"+str(auc))\n",
        "\n",
        "for c in classifiers:\n",
        "    c.fit(x_train, y_train)\n",
        "    y_pred = c.predict_proba(x_test)[:, 1]\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
        "    auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
        "    plt.plot(fpr,tpr,label=\" AUC=\"+str(auc))\n",
        "\n",
        "#add legend\n",
        "plt.legend()"
      ],
      "id": "724117fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Instantiate the classfiers and make a list\n",
        "classifiers = [LogisticRegression(random_state=123), \n",
        "               GaussianNB(), \n",
        "               KNeighborsClassifier(), \n",
        "               DecisionTreeClassifier(random_state=123),\n",
        "               RandomForestClassifier(random_state=123)]\n",
        "\n",
        "# Define a result table as a DataFrame\n",
        "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
        "X_train = x_train\n",
        "X_test = x_test\n",
        "# Train the models and record the results\n",
        "for cls in classifiers:\n",
        "    model = cls.fit(X_train, y_train)\n",
        "    yproba = model.predict_proba(X_test)[::,1]\n",
        "    \n",
        "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
        "    auc = roc_auc_score(y_test, yproba)\n",
        "    \n",
        "    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
        "                                        'fpr':fpr, \n",
        "                                        'tpr':tpr, \n",
        "                                        'auc':auc}, ignore_index=True)\n",
        "\n",
        "# Set name of the classifiers as index labels\n",
        "result_table.set_index('classifiers', inplace=True)\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "for i in result_table.index:\n",
        "    plt.plot(result_table.loc[i]['fpr'], \n",
        "             result_table.loc[i]['tpr'], \n",
        "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
        "    \n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"Flase Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "id": "6bab31a7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Precision Recall Curve "
      ],
      "id": "e65efc8e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Instantiate the classfiers and make a list\n",
        "classifiers = [LogisticRegression(random_state=123), \n",
        "               GaussianNB(), \n",
        "               KNeighborsClassifier(), \n",
        "               DecisionTreeClassifier(random_state=123),\n",
        "               RandomForestClassifier(random_state=123)]\n",
        "\n",
        "# Define a result table as a DataFrame\n",
        "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
        "X_train = x_train\n",
        "X_test = x_test\n",
        "# Train the models and record the results\n",
        "for cls in classifiers:\n",
        "    model = cls.fit(X_train, y_train)\n",
        "    yproba = model.predict_proba(X_test)[::,1]\n",
        "    \n",
        "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
        "    auc = roc_auc_score(y_test, yproba)\n",
        "    \n",
        "    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
        "                                        'fpr':fpr, \n",
        "                                        'tpr':tpr, \n",
        "                                        'auc':auc}, ignore_index=True)\n",
        "\n",
        "# Set name of the classifiers as index labels\n",
        "result_table.set_index('classifiers', inplace=True)\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "for i in result_table.index:\n",
        "    plt.plot(result_table.loc[i]['fpr'], \n",
        "             result_table.loc[i]['tpr'], \n",
        "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
        "    \n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"Flase Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()\n"
      ],
      "id": "19bce4d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# predict probabilities\n",
        "lr_probs = lr.predict_proba(x_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "# predict class values\n",
        "yhat = lr.predict(x_test)\n",
        "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
        "#lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
        "# summarize scores\n",
        "#print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
        "# plot the precision-recall curves\n",
        "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
        "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "\n",
        "\n",
        "lr_probs = dtc.predict_proba(x_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "# predict class values\n",
        "yhat = lr.predict(x_test)\n",
        "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
        "#lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
        "# summarize scores\n",
        "#print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
        "# plot the precision-recall curves\n",
        "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
        "#pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_recall, lr_precision, marker='.', label='Decision Tree')\n",
        "\n",
        "\n",
        "lr_probs = rfc.predict_proba(x_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "# predict class values\n",
        "yhat = lr.predict(x_test)\n",
        "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
        "#lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
        "# summarize scores\n",
        "#print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
        "# plot the precision-recall curves\n",
        "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
        "#pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_recall, lr_precision, marker='.', label='Random Forest')\n",
        "\n",
        "lr_probs = modelNB.predict_proba(x_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "# predict class values\n",
        "yhat = lr.predict(x_test)\n",
        "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
        "#lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
        "# summarize scores\n",
        "#print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
        "# plot the precision-recall curves\n",
        "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
        "#pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_recall, lr_precision, marker='.', label='Naive Bayes')\n",
        "\n",
        "\n",
        "lr_probs = knn.predict_proba(x_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "# predict class values\n",
        "yhat = lr.predict(x_test)\n",
        "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
        "#lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
        "# summarize scores\n",
        "#print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
        "# plot the precision-recall curves\n",
        "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
        "#pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_recall, lr_precision, marker='.', label='KNN')\n",
        "\n",
        "\n",
        "pyplot.xlabel('Recall')\n",
        "pyplot.ylabel('Precision')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "id": "5ebbdd64",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}